{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc391ee7-fa2d-4aa4-a7df-e0940989ec89",
   "metadata": {},
   "source": [
    "## SQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fdd9e4d-2980-4998-9189-598ca3793abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QP\n",
    "\n",
    "# Linesearch with penalty\n",
    "\n",
    "# Active set strategy\n",
    "\n",
    "# BFGS for approximating Hessian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d84531af-e3d1-4123-8fcc-f3eb9692a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch as t\n",
    "from torch.autograd.functional import jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8646cb54-ac25-47aa-b520-953a22604305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\"\"\"\n",
    "Decision variable: x0\n",
    "State variables: x1\n",
    "\"\"\"\n",
    "\n",
    "m = 2 # No. of constraints\n",
    "n = 2 # No. of variables\n",
    "d = n - m # No. of decision variables\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    # Define the objective function\n",
    "    f = lambda x: x[0] ** 2 + (x[1] - 3) ** 2\n",
    "    # Define the constraints\n",
    "    g1 = lambda x: (x[1] ** 2) - (2 * x[0])\n",
    "    g2 = lambda x: (x[1] - 1) ** 2 + (5 * x[0]) - 15\n",
    "    \n",
    "    return f(x), g1(x), g2(x)\n",
    "\n",
    "\n",
    "def Lag(x, mu):\n",
    "\n",
    "    # Define the objective function\n",
    "    f = lambda x: x[0] ** 2 + (x[1] - 3) ** 2\n",
    "    # Define the constraints\n",
    "    g1 = lambda x: (x[1] ** 2) - (2 * x[0])\n",
    "    g2 = lambda x: (x[1] - 1) ** 2 + (5 * x[0]) - 15\n",
    "\n",
    "    # return f(x) + mu.T @ t.tensor([[g1(x)], [g2(x)]])\n",
    "    return f(x) + mu[0] * g1(x) + mu[1] * g2(x)\n",
    "\n",
    "\n",
    "# Compute Jacobian\n",
    "def jac(x, n=n):\n",
    "    J = t.zeros((m+1, n))\n",
    "    for i in range(m+1):\n",
    "       J[i] =  jacobian(f, (x))[i] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "\n",
    "# Compute Jacobian\n",
    "def jacL(x, mu, n=n):\n",
    "    J = t.zeros((1, n))\n",
    "    # for i in range(n):\n",
    "    J[0] =  jacobian(Lag, (x, mu))[0] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "# Evaluate Constraints\n",
    "def hFunc(x, m=m, n=n):\n",
    "    H = t.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        H[i] =  f(x)[d + 1 + i]\n",
    "    return H\n",
    "\n",
    "\n",
    "def Lag1(x, mu):\n",
    "\n",
    "    return f(x)[0] + mu @ hFunc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d126eb4-5a6b-4787-95ae-17544596dbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BFGS(W, x, s, dx, mu):\n",
    "    Lx0 =  jacL(x - dx, mu)\n",
    "    # print(Lx0.shape)\n",
    "    Lx1 =  jacL(x, mu)\n",
    "    # print(Lx1.shape)\n",
    "    Q = dx.T @ W @ dx\n",
    "    # print(dx)\n",
    "    # print(dx @ (Lx1 - Lx0).T)\n",
    "    # print((Lx1 - Lx0))\n",
    "    L = Lx1 - Lx0\n",
    "    \n",
    "    if dx @ (Lx1 - Lx0).T >= 0.2 * Q:\n",
    "        theta = 1\n",
    "        # print(theta)\n",
    "    else:\n",
    "        theta = (0.8 * Q) / (Q - dx @ (Lx1 - Lx0).T)\n",
    "        # print(theta)\n",
    "\n",
    "    y = theta * (Lx1 - Lx0) + (1 - theta) * (W @ dx)\n",
    "    # print(W)\n",
    "    # print((s.T @ W @ s))\n",
    "    # W = W + ((y.T @ y) / (y @ s.T)) - (((W @ s).reshape(-1, 1) @ (s.T @ W).reshape(1, -1)) / (s.T @ W @ s))\n",
    "    W = W + ((y.T @ y) / (y @ dx.T)) - (((W @ dx).reshape(-1, 1) @ (dx.T @ W).reshape(1, -1)) / (dx.T @ W @ dx))\n",
    "\n",
    "    # print((W))\n",
    "    \n",
    "    return W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b25ddb-ef23-48cd-97b2-9bdad6da5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armijo Line \n",
    "def F(alpha, x, s, wj):\n",
    "    dx = alpha * s\n",
    "    H = hFunc(x + dx)\n",
    "    F = f(x + dx)[0] + t.sum(wj.T @ t.max(t.tensor([0]), H))\n",
    "    return F\n",
    "\n",
    "def phi(alpha, x, s, wj, t0=0.5):\n",
    "    phi = F(alpha, x, t.zeros((2)), wj) + t0 * alpha * dFda(alpha, x, s, wj) \n",
    "\n",
    "    return phi\n",
    "\n",
    "def dFda(alpha, x, s, wj):\n",
    "    J =  jac(x)\n",
    "    H = hFunc(x)\n",
    "    \n",
    "    dgdx = J[1:, :]\n",
    "    # print(dgdx.shape)\n",
    "    \n",
    "    dgda = dgdx @ s.reshape(-1, 1)\n",
    "    # print(dgda.shape)\n",
    "    dgda[(t.max(t.tensor([0]), H) <= 0)] = 0\n",
    "    \n",
    "    dFda = J[0, :].T @ s + t.sum(wj.T @ dgda)\n",
    "    \n",
    "    return dFda\n",
    "\n",
    "def lineSearch(x, s, mu, wj0, K=25):\n",
    "    alpha = 1\n",
    "    i = 0\n",
    "      \n",
    "    wj = t.max(t.abs(mu), 0.5 * (wj0 + t.abs(mu)))\n",
    "    \n",
    "    # print('Fa initial: ', F(alpha, x, s, wj))\n",
    "    # print('phi initial: ', phi(alpha, x, s, wj))\n",
    "    # print('dFda initial: ',dFda(alpha, x, s, wj))\n",
    "    \n",
    "\n",
    "    while F(alpha, x, s, wj) + 1e-10  > phi(alpha, x, s, wj) and i < K:\n",
    "        \n",
    "        \n",
    "        alpha = 0.5 * alpha\n",
    "        print(alpha, i)\n",
    "        \n",
    "        F1 = F(alpha, x, s, wj)\n",
    "        phi1 = phi(alpha, x, s, wj)\n",
    "        dFda1 = dFda(alpha, x, s, wj)\n",
    "        # print('\\nFa: ', F1)\n",
    "        # print('dFda: ', dFda1)\n",
    "        # print('phi: ', phi1)\n",
    "\n",
    "        i += 1\n",
    "    return alpha, wj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94589a39-ded5-4a93-a25b-984c067d441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def activeSet(x, s, mu, active, flag):\n",
    "    A = jac(x)[1:, :]\n",
    "    H = hFunc(x)\n",
    "    \n",
    "    constraintQP = t.round(A @ s.reshape(-1, 1) + H, decimals=3)\n",
    "    \n",
    "    val1 , idx1 = t.max(constraintQP, 0)\n",
    "    # print('Constraint:', constraintQP)\n",
    "    val2 , idx2 = t.min(mu, 0)\n",
    "    \n",
    "    if val2 < 0:\n",
    "        # remove.append(idx2.item())\n",
    "        active.pop(idx2.item())\n",
    "        # print('Remove indices; ', idx2)\n",
    "    \n",
    "    else:\n",
    "        if val1  > 0:\n",
    "            # add.append(idx1.item())\n",
    "            active.append(idx1.item())\n",
    "            # print('Add indices; ', idx1)\n",
    "\n",
    "        else:\n",
    "            flag = True\n",
    "    \n",
    "    # active.append(add)\n",
    "    # active.pop(remove)\n",
    "    \n",
    "    active = [*set(active)]\n",
    "    \n",
    "    return active, flag\n",
    "\n",
    "\n",
    "\n",
    "def solveQP(x, W, mu, active):\n",
    "    # W = t.eye(n)\n",
    "    A = jac(x)[1:, :]\n",
    "    dfx = jac(x)[0]\n",
    "    h = hFunc(x)\n",
    "    # mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "\n",
    "    if len(active) == 0:\n",
    "        X = t.linalg.solve(W, -dfx)\n",
    "        s = X\n",
    "        \n",
    "    else:\n",
    "        A = A[active]\n",
    "        h = h[active]\n",
    "        \n",
    "        C = t.vstack((t.hstack((W, A.T)), t.hstack((A, t.zeros(A.shape[0], A.shape[0])))))\n",
    "        d = - t.vstack((dfx.reshape(-1, 1), h)) # Check if this negative sign is important\n",
    "        \n",
    "        X = t.linalg.solve(C, d)\n",
    "        s = X[:n, :]\n",
    "        with t.no_grad():\n",
    "            mu[active] = X[n:, :].T\n",
    "\n",
    "    return s, mu\n",
    "\n",
    "\n",
    "\n",
    "def QP(x, W):\n",
    "    mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "    \n",
    "    flag = False\n",
    "    active = []\n",
    "    # i = 0\n",
    "    # print('Flag:', flag)\n",
    "    while flag == False:\n",
    "        s, mu = solveQP(x, W, mu, active)\n",
    "        active, flag = activeSet(x, s, mu, active, flag)\n",
    "        # print('Counter', i)\n",
    "        # i += 1\n",
    "        \n",
    "    return s.reshape(1, -1)[0], mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fbb998-23d3-4215-af65-2a2e1e57791c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Initialization\n",
    "def SQP(x):\n",
    "    # Initialize variables\n",
    "    \n",
    "    \n",
    "    mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "    W = t.eye(n, dtype=t.float)\n",
    "    wj = t.tensor([0., 0.], dtype=t.float)\n",
    "    \n",
    "    tol = 1e-3 # Error threshold\n",
    "    e = t.norm(jacL(x, mu))\n",
    "    \n",
    "    xSol = x.detach().numpy()\n",
    "    fVal = [f(x)[0].item()]\n",
    "    alphaSol = [1]\n",
    "    eVal = [e]\n",
    "\n",
    "    k = 0\n",
    "    while e > tol:\n",
    "        \n",
    "        s, muNext = QP(x, W)\n",
    "        # print(f's: {s}')\n",
    "\n",
    "        \n",
    "        # Part 4.1\n",
    "        # Inexact line search\n",
    "        alpha, wj = lineSearch(x, s, mu, wj)\n",
    "        mu = muNext\n",
    "        \n",
    "        # print('Mu: ', mu)\n",
    "        \n",
    "        # alpha = 1\n",
    "\n",
    "        # Update the point \n",
    "        dx = alpha * s\n",
    "        with t.no_grad():\n",
    "            x = x + dx\n",
    "        \n",
    "        # Part 4.4\n",
    "        # LM Solver\n",
    "        W = BFGS(W, x, s, dx, muNext)\n",
    "\n",
    "        # Part 4.5\n",
    "        e = t.norm(jacL(x, muNext))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(e)\n",
    "        \n",
    "        # Store important information in every iteration\n",
    "        xSol = np.vstack((xSol, x.detach().numpy())) # Record x values in each iteration\n",
    "        fVal.append(f(x)[0].item()) # Record f values in each iteration\n",
    "        alphaSol.append(alpha) # Record alpha values in each iteration\n",
    "        eVal.append(e)\n",
    "        # print(f'k: {k}, x: {x}\\n')\n",
    "        k += 1\n",
    "        print (f\"Iteration: {k:<5} Alpha: {alpha:<10} x: {str(x.detach().numpy()) :<25} f(x): {fVal[k]:<25} Error: {e:<20}\\n\")\n",
    "    return xSol, fVal, alphaSol, eVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da2cb977-eebf-4b9c-b9a6-1cbac9d724bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Initial guess does not lie in the feasible domain!!!",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Initial guess does not lie in the feasible domain!!!\n"
     ]
    }
   ],
   "source": [
    "x = t.tensor([10., 0.], dtype=t.float, requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val1 , idx1 = t.max(hFunc(x), 0)\n",
    "if val1  > 0:\n",
    "    sys.exit('Initial guess does not lie in the feasible domain!!!')\n",
    "\n",
    "xSol, fVal, alphaSol, eVal = SQP(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c8d11-7da8-4971-98b5-25e328426c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e953ea7-ab2f-4452-82dc-6d7b57c3ce94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65b9a2-cc04-4d6f-9397-2101d6fc7feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
