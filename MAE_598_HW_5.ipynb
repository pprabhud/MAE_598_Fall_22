{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ed1f1c-1c16-49b3-8e4e-b1532a6b15d4",
   "metadata": {},
   "source": [
    "# MAE 598: Design Optimization - Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5cf76-9170-4eb0-a65b-b619645a21dc",
   "metadata": {},
   "source": [
    "## Problem 1: Sequential Quadratic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e847fb-b730-423d-bd35-0c1b2a9bb007",
   "metadata": {},
   "source": [
    "**Objective function**\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\\quad & \\min_{x_{1}, x_{2}} \\quad f(x) = x_{1}^2 +  (x_{2} - 3)^2 \\\\\n",
    "\\quad & s.t. \\\\\n",
    "\\quad & g_1(x) = x_{2}^2 - 2x_{1} \\le 0 \\\\\n",
    "\\quad & g_2(x) = (x_{2} - 1)^2 + 5x_{1} - 15 \\le 0 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Starting point is chosen as $ x = [1, 1] $\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08110bd6-1cea-459c-848b-0255cd4230d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch as t\n",
    "from torch.autograd.functional import jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6280a32a-6af2-44e2-9927-e24d78ca12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Functions for evaluating objective function, constraints, Langrangian, Jacobians\n",
    "\n",
    "m = 2 # No. of constraints\n",
    "n = 2 # No. of variables\n",
    "\n",
    "\n",
    "# Evaluate obejective function and constraints\n",
    "def f(x):\n",
    "    # Define the objective function\n",
    "    f = lambda x: x[0] ** 2 + (x[1] - 3) ** 2\n",
    "    # Define the constraints\n",
    "    g1 = lambda x: (x[1] ** 2) - (2 * x[0])\n",
    "    g2 = lambda x: (x[1] - 1) ** 2 + (5 * x[0]) - 15\n",
    "    return f(x), g1(x), g2(x)\n",
    "\n",
    "\n",
    "# Compute Lagrangian\n",
    "def Lag(x, mu):\n",
    "    # Return the lagrangian\n",
    "    return f(x)[0] + mu @ gVals(x)\n",
    "\n",
    "\n",
    "# Compute Jacobian\n",
    "def jac(x, n=n):\n",
    "    J = t.zeros((m+1, n))\n",
    "    for i in range(m+1):\n",
    "       J[i] =  jacobian(f, (x))[i] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "\n",
    "# Compute Jacobian of the Lagrangian\n",
    "def jacL(x, mu, n=n):\n",
    "    J = t.zeros((1, n))\n",
    "    J =  jacobian(Lag, (x, mu))[0] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "\n",
    "# Evaluate Constraints\n",
    "def gVals(x, m=m, n=n):\n",
    "    G = t.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        G[i] =  f(x)[1 + i]\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7366eaa6-02f8-4a16-946d-45ded4501944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Armijo Line \n",
    "\n",
    "# Evaluate merit function\n",
    "def F(alpha, x, s, wj):\n",
    "    dx = alpha * s\n",
    "    G = gVals(x + dx)\n",
    "    F = f(x + dx)[0] + t.sum(wj.T @ t.max(t.tensor([0]), G))\n",
    "    return F\n",
    "\n",
    "# Evaluate auxillary function phi\n",
    "def phi(alpha, x, s, wj, t0=0.5):\n",
    "    phi = F(alpha, x, t.zeros((2)), wj) + t0 * alpha * dFda(alpha, x, s, wj) \n",
    "    return phi\n",
    "\n",
    "# Evaluate derivative of the merit function\n",
    "def dFda(alpha, x, s, wj):\n",
    "    J = jac(x)\n",
    "    G = gVals(x)\n",
    "    \n",
    "    dgdx = J[1:, :]\n",
    "    dgda = dgdx @ s.reshape(-1, 1)\n",
    "    dgda[(t.max(t.tensor([0]), G) <= 0)] = 0\n",
    "    \n",
    "    dFda = J[0, :].T @ s + t.sum(wj.T @ dgda)\n",
    "    return dFda\n",
    "\n",
    "def lineSearch(x, s, mu, wj0, K=25):\n",
    "    alpha = 1\n",
    "    i = 0\n",
    "      \n",
    "    # Update weights\n",
    "    wj = t.max(t.abs(mu), 0.5 * (wj0 + t.abs(mu)))\n",
    "    \n",
    "    while F(alpha, x, s, wj) + 1e-10  > phi(alpha, x, s, wj) and i < K:\n",
    "        alpha = 0.5 * alpha  # Update alpha\n",
    "        i += 1\n",
    "    return alpha, wj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66852aa-60d6-44ab-9ccb-a69e67064114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Solve the QP subproblem\n",
    "\n",
    "# Active set strategy\n",
    "def activeSet(x, s, mu, active, flag):\n",
    "    A = jac(x)[1:, :]\n",
    "    G = gVals(x)\n",
    "    \n",
    "    # Evaluate constraints of the QP system\n",
    "    constraintQP = t.round(A @ s.reshape(-1, 1) + G, decimals=3)\n",
    "    \n",
    "    # Check if the constraints are violated and Lagrange multipliers\n",
    "    val1 , idx1 = t.max(constraintQP, 0)\n",
    "    val2 , idx2 = t.min(mu, 0)\n",
    "    # Condition for mu\n",
    "    if val2 < 0:\n",
    "        active.pop(idx2.item()) # Remove the index of the most negative mu from the active set\n",
    "    else:\n",
    "         # Condition for g\n",
    "        if val1  > 0:\n",
    "            active.append(idx1.item()) # Add the index of the most violated constraint to the active set\n",
    "        else:\n",
    "            flag = True # Set the flag to true once the KKT conditions are satisfied\n",
    "    \n",
    "    active = [*set(active)] # Keep unique indices\n",
    "    \n",
    "    return active, flag\n",
    "\n",
    "\n",
    "# Solve the system of equations\n",
    "def solveQP(x, W, mu, active):\n",
    "    # Setup the system of equations for the QP subproblem\n",
    "    A = jac(x)[1:, :]\n",
    "    dfx = jac(x)[0]\n",
    "    G = gVals(x)\n",
    "\n",
    "    # Solution when the active set is empty\n",
    "    if len(active) == 0:\n",
    "        X = t.linalg.solve(W, -dfx)\n",
    "        s = X\n",
    "    # Solution when the active set is non-empty\n",
    "    else:\n",
    "        A = A[active]\n",
    "        G = G[active]\n",
    "        # Construct the LHS matrix [[W, A.T], [A, 0]]\n",
    "        C = t.vstack((t.hstack((W, A.T)), t.hstack((A, t.zeros(A.shape[0], A.shape[0])))))\n",
    "        # Construct the RHS matrix\n",
    "        d = - t.vstack((dfx.reshape(-1, 1), G)) # Check if this negative sign is important\n",
    "        # Solve\n",
    "        X = t.linalg.solve(C, d)\n",
    "        # Slice the solution vector into s and mu\n",
    "        s = X[:n, :]\n",
    "        with t.no_grad():\n",
    "            mu[active] = X[n:, :].T\n",
    "\n",
    "    return s, mu\n",
    "\n",
    "\n",
    "# Formulate the QP subproblem\n",
    "def QP(x, W):\n",
    "    mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "    flag = False # Flag to monitor if the KKT conditions are satisfied\n",
    "    active = [] # Start with an empty active set\n",
    "    \n",
    "    # Iterate till the KKT conditions are met\n",
    "    while flag == False:\n",
    "        s, mu = solveQP(x, W, mu, active)\n",
    "        active, flag = activeSet(x, s, mu, active, flag)\n",
    "\n",
    "    return s.reshape(1, -1)[0], mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b70358-3ebe-4a88-96f6-ba64feb951a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Approximate the Hessian using Quasi-Newton method (BFGS)\n",
    "\n",
    "def BFGS(W, x, s, dx, mu):\n",
    "    Lx0 =  jacL(x - dx, mu)\n",
    "    Lx1 =  jacL(x, mu)\n",
    "    L = Lx1 - Lx0\n",
    "    Q = dx.T @ W @ dx\n",
    "\n",
    "    # Augment y in order to satisfy the curvature condition\n",
    "    if dx @ L.T >= 0.2 * Q:\n",
    "        theta = 1\n",
    "    else:\n",
    "        theta = (0.8 * Q) / (Q - dx @ L.T)\n",
    "    # Update y\n",
    "    y = theta * L + (1 - theta) * (W @ dx)\n",
    "    # Rank 2 update of the Hessian matrix\n",
    "    W = W + ((y.T @ y) / (y @ dx.T)) - (((W @ dx).reshape(-1, 1) @ (dx.T @ W).reshape(1, -1)) / (dx.T @ W @ dx))\n",
    "   \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1d5d8b-1583-443f-bdcb-cf53fe7389e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Sequential Quadratic programming\n",
    "# Combine all the functions to formulate and solve SQP\n",
    "def SQP(x):\n",
    "    # Initialize variables   \n",
    "    mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "    wj = t.tensor([0., 0.], dtype=t.float)\n",
    "    W = t.eye(n, dtype=t.float)\n",
    "    \n",
    "    tol = 1e-3 # Error threshold\n",
    "    e = t.norm(jacL(x, mu))\n",
    "    \n",
    "    xSol = x.detach().numpy()\n",
    "    fVal = [f(x)[0].item()]\n",
    "    alphaSol = [1]\n",
    "    eVal = [e]\n",
    "\n",
    "    k = 0\n",
    "    while e > tol:\n",
    "        # Solve the QP subproblem and find the new step direction, Langrange multipliers\n",
    "        s, muNext = QP(x, W)\n",
    "\n",
    "        # Inexact line search\n",
    "        alpha, wj = lineSearch(x, s, mu, wj) # retyrn optimal step size and penalty weights\n",
    "        mu = muNext # Update mu\n",
    "        \n",
    "        # Update the solution point \n",
    "        dx = alpha * s\n",
    "        with t.no_grad():\n",
    "            x = x + dx\n",
    "        \n",
    "        # Approximate the Hessian matrix\n",
    "        W = BFGS(W, x, s, dx, muNext)\n",
    "\n",
    "        # Evaluate the error\n",
    "        e = t.norm(jacL(x, muNext))\n",
    "        \n",
    "        # Store important information in every iteration\n",
    "        xSol = np.vstack((xSol, x.detach().numpy())) # Record x values in each iteration\n",
    "        fVal.append(f(x)[0].item()) # Record f values in each iteration\n",
    "        alphaSol.append(alpha) # Record alpha values in each iteration\n",
    "        eVal.append(e)\n",
    "\n",
    "        k += 1\n",
    "        print (f\"Iteration: {k:<5} Alpha: {alpha:<10} x: {str(x.detach().numpy()) :<25} f(x): {fVal[k]:<25} Error: {e:<20}\")\n",
    "    return xSol, fVal, alphaSol, eVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316ca53a-89e3-495a-a926-9d510e455118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1     Alpha: 0.5        x: [1.375 1.625]             f(x): 3.78125                   Error: 1.71875             \n",
      "Iteration: 2     Alpha: 1          x: [1.0312666 1.4471256]     f(x): 3.4749298095703125        Error: 0.325317919254303   \n",
      "Iteration: 3     Alpha: 1          x: [1.0595775 1.4557573]     f(x): 3.507390022277832         Error: 0.010186470113694668\n",
      "Iteration: 4     Alpha: 1          x: [1.0602411 1.4561876]     f(x): 3.5074679851531982        Error: 0.0003641493967734277\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "x = t.tensor([1., 1.], dtype=t.float, requires_grad=True)\n",
    "\n",
    "# Check if the starting point is valid\n",
    "val1 , idx1 = t.max(gVals(x), 0)\n",
    "if val1  > 0:\n",
    "    sys.exit('Initial guess does not lie in the feasible domain!!!')\n",
    "\n",
    "# Solve\n",
    "xSol, fVal, alphaSol, eVal = SQP(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05da1a-658e-4a95-870a-3bc4f038caa9",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07be94-75c0-4697-880a-8c340adc53e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
