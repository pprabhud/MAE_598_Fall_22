{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc391ee7-fa2d-4aa4-a7df-e0940989ec89",
   "metadata": {},
   "source": [
    "## SQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdd9e4d-2980-4998-9189-598ca3793abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QP\n",
    "\n",
    "# Linesearch with penalty\n",
    "\n",
    "# Active set strategy\n",
    "\n",
    "# BFGS for approximating Hessian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84531af-e3d1-4123-8fcc-f3eb9692a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.functional import jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8646cb54-ac25-47aa-b520-953a22604305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\"\"\"\n",
    "Decision variable: x0\n",
    "State variables: x1\n",
    "\"\"\"\n",
    "\n",
    "m = 2 # No. of constraints\n",
    "n = 2 # No. of variables\n",
    "d = n - m # No. of decision variables\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    # Define the objective function\n",
    "    f = lambda x: x[0] ** 2 + (x[1] - 3) ** 2\n",
    "    # Define the constraints\n",
    "    g1 = lambda x: (x[1] ** 2) - (2 * x[0])\n",
    "    g2 = lambda x: (x[1] - 1) ** 2 + (5 * x[0]) - 15\n",
    "    \n",
    "    return f(x), g1(x), g2(x)\n",
    "\n",
    "\n",
    "def Lag(x, mu):\n",
    "\n",
    "    # Define the objective function\n",
    "    f = lambda x: x[0] ** 2 + (x[1] - 3) ** 2\n",
    "    # Define the constraints\n",
    "    g1 = lambda x: (x[1] ** 2) - (2 * x[0])\n",
    "    g2 = lambda x: (x[1] - 1) ** 2 + (5 * x[0]) - 15\n",
    "\n",
    "    # return f(x) + mu.T @ t.tensor([[g1(x)], [g2(x)]])\n",
    "    return f(x) + mu[0] * g1(x) + mu[1] * g2(x)\n",
    "\n",
    "\n",
    "# Compute Jacobian\n",
    "def jac(x, n=n):\n",
    "    J = t.zeros((m+1, n))\n",
    "    for i in range(m+1):\n",
    "       J[i] =  jacobian(f, (x))[i] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "\n",
    "# Compute Jacobian\n",
    "def jacL(x, mu, n=n):\n",
    "    J = t.zeros((1, n))\n",
    "    # for i in range(n):\n",
    "    J[0] =  jacobian(Lag, (x, mu))[0] # 'jacobian' function in Pytorch returns a tuple of tensors. Copying each tensor slice into a new tensor for the ease of indexing.\n",
    "    return J\n",
    "\n",
    "# Evaluate Constraints\n",
    "def hFunc(x, m=m, n=n):\n",
    "    H = t.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        H[i] =  f(x)[d + 1 + i]\n",
    "    return H\n",
    "\n",
    "\n",
    "def Lag1(x, mu):\n",
    "\n",
    "    return f(x)[0] + mu @ hFunc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b25ddb-ef23-48cd-97b2-9bdad6da5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armijo Line \n",
    "def F(alpha, x, s, wj):\n",
    "    dx = alpha * s\n",
    "    H = hFunc(x + dx)\n",
    "    \n",
    "    F = f(x + dx)[0] + t.sum(wj.T @ t.max(t.tensor([0]), H))\n",
    "    return F\n",
    "\n",
    "def phi(alpha, x, s, wj, t0=0.5):\n",
    "    phi = F(alpha, x, s, wj) + t0 * alpha * dFda(alpha, x, s, wj) \n",
    "    \n",
    "    return phi\n",
    "\n",
    "def dFda(alpha, x, s, wj):\n",
    "    J =  jac(x)\n",
    "    H = hFunc(x)\n",
    "    \n",
    "    dgdx = J[1:, :]\n",
    "    # print(dgdx.shape)\n",
    "    \n",
    "    dgda = dgdx @ s.reshape(-1, 1)\n",
    "    # print(dgda.shape)\n",
    "    \n",
    "    dgda[(t.max(t.tensor([0]), H) <= 0)] = 0\n",
    "    \n",
    "    dFda = J[0, :].T @ s + t.sum(wj.T @ dgda)\n",
    "    \n",
    "    return dFda\n",
    "\n",
    "def lineSearch(x, s, mu, wj0, k, K=25):\n",
    "    alpha = 1\n",
    "    i = 0\n",
    "    \n",
    "    if k == 0:\n",
    "        wj = t.abs(mu)\n",
    "        print('wj:', wj)\n",
    "    \n",
    "    else:\n",
    "        wj = t.max(t.abs(mu), 0.5 * (wj0 + t.abs(mu)))\n",
    "        print('wj:', wj)\n",
    "        \n",
    "    print('\\nFa: ', F(alpha, x, s, wj))\n",
    "    print('\\nphi: ', phi(alpha, x, s, wj))\n",
    "    print('\\ndFda: ',dFda(alpha, x, s, wj))\n",
    "        \n",
    "    while F(alpha, x, s, wj) > phi(alpha, x, s, wj) and i < K:\n",
    "        alpha = 0.5 * alpha\n",
    "        print(alpha)\n",
    "        # wj = t.max(t.abs(mu), 0.5 * (wj + t.abs(mu)))\n",
    "        i += 1\n",
    "    return alpha, wj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3ff6b8-6864-4e04-bed4-66998822251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = t.tensor([1., -0.1], dtype=t.float, requires_grad=True)\n",
    "# mu = t.tensor([1., 1.], dtype=t.float, requires_grad=True)\n",
    "# W = t.eye(n)\n",
    "# # s = t.tensor([-1.61881188, 6.23811881], requires_grad=True)\n",
    "\n",
    "# s = t.tensor([-1.6, 6.5], requires_grad=True)\n",
    "# # wt = t.tensor([1., 1.], dtype=t.float)\n",
    "# wt = t.tensor([5., 5.], dtype=t.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18585e10-1a47-4f15-a096-2a8b18cda85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, w1 = lineSearch(x, s, mu, wt, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d126eb4-5a6b-4787-95ae-17544596dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(W, x, s, dx, mu):\n",
    "    Lx0 =  jacL(x - dx, mu)\n",
    "    # print(Lx0.shape)\n",
    "    Lx1 =  jacL(x, mu)\n",
    "    # print(Lx1.shape)\n",
    "    Q = dx.T @ W @ dx\n",
    "    # print(dx)\n",
    "    # print(dx @ (Lx1 - Lx0).T)\n",
    "    # print((Lx1 - Lx0))\n",
    "    \n",
    "    if dx @ (Lx1 - Lx0).T >= 0.2 * Q:\n",
    "        theta = 1\n",
    "        # print(theta)\n",
    "    else:\n",
    "        theta = (0.8 * Q) / (Q - dx @ (Lx1 - Lx0).T)\n",
    "        # print(theta)\n",
    "\n",
    "    y = theta * (Lx1 - Lx0) + (1 - theta) * (W @ dx)\n",
    "    # print(W)\n",
    "    # print((s.T @ W @ s))\n",
    "    W = W + ((y.T @ y) / (y @ s.T)) - (((W @ s).reshape(-1, 1) @ (s.T @ W).reshape(1, -1)) / (s.T @ W @ s))\n",
    "    # print((W))\n",
    "    \n",
    "    return W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ce134-029f-4f5b-be24-15c1b277b669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94589a39-ded5-4a93-a25b-984c067d441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activeSet(x, s, mu, active, flag):\n",
    "    A = jac(x)[1:, :]\n",
    "    H = hFunc(x)\n",
    "    \n",
    "    constraintQP = t.round(A @ s.reshape(-1, 1) + H, decimals=3)\n",
    "    \n",
    "    val1 , idx1 = t.max(constraintQP, 0)\n",
    "    # print('Constraint:', constraintQP)\n",
    "    val2 , idx2 = t.min(mu, 0)\n",
    "    \n",
    "    if val2 < 0:\n",
    "        # remove.append(idx2.item())\n",
    "        active.pop(idx2.item())\n",
    "        # print('Remove indices; ', idx2)\n",
    "    \n",
    "    else:\n",
    "        if val1  > 0:\n",
    "            # add.append(idx1.item())\n",
    "            active.append(idx1.item())\n",
    "            # print('Add indices; ', idx1)\n",
    "\n",
    "        else:\n",
    "            flag = True\n",
    "    \n",
    "    # active.append(add)\n",
    "    # active.pop(remove)\n",
    "    \n",
    "    active = [*set(active)]\n",
    "    \n",
    "    return active, flag\n",
    "\n",
    "\n",
    "\n",
    "def solveQP(x, W, mu, active):\n",
    "    # W = t.eye(n)\n",
    "    A = jac(x)[1:, :]\n",
    "    dfx = jac(x)[0]\n",
    "    h = hFunc(x)\n",
    "    # mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "\n",
    "    if len(active) == 0:\n",
    "        X = t.linalg.solve(W, -dfx)\n",
    "        s = X\n",
    "        \n",
    "    else:\n",
    "        A = A[active]\n",
    "        h = h[active]\n",
    "        \n",
    "        C = t.vstack((t.hstack((W, A.T)), t.hstack((A, t.zeros(A.shape[0], A.shape[0])))))\n",
    "        d = - t.vstack((dfx.reshape(-1, 1), h)) # Check if this negative sign is important\n",
    "        \n",
    "        X = t.linalg.solve(C, d)\n",
    "        s = X[:n, :]\n",
    "        with t.no_grad():\n",
    "            mu[active] = X[n:, :].T\n",
    "\n",
    "    return s, mu\n",
    "\n",
    "\n",
    "\n",
    "def QP(x, W):\n",
    "    mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "    \n",
    "    flag = False\n",
    "    active = []\n",
    "    # i = 0\n",
    "    # print('Flag:', flag)\n",
    "    while flag == False:\n",
    "        s, mu = solveQP(x, W, mu, active)\n",
    "        active, flag = activeSet(x, s, mu, active, flag)\n",
    "        # print('Counter', i)\n",
    "        # i += 1\n",
    "        \n",
    "    return s.reshape(1, -1)[0], mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fbb998-23d3-4215-af65-2a2e1e57791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Initialization\n",
    "def SQP(x, mu, W, wj):\n",
    "    # Initialize variables\n",
    "    e = t.norm(jacL(x, mu))\n",
    "    tol = 1e-3 # Error threshold\n",
    "\n",
    "    xSol = x.detach().numpy()\n",
    "    fVal = [f(x)[0].item()]\n",
    "    alphaSol = [1]\n",
    "    eVal = [e]\n",
    "\n",
    "    k = 0\n",
    "    while e > tol:\n",
    "        \n",
    "        s, mu = QP(x, W)\n",
    "        # print(s)\n",
    "\n",
    "        \n",
    "        # Part 4.1\n",
    "        # Inexact line search\n",
    "        # alpha, wj = lineSearch(x, s, mu, wj, k)\n",
    "        alpha = 0.5\n",
    "\n",
    "        # Update the point \n",
    "        dx = alpha * s\n",
    "        with t.no_grad():\n",
    "            x = x + alpha * dx\n",
    "        \n",
    "        # Part 4.4\n",
    "        # LM Solver\n",
    "        W = BFGS(W, x, s, dx, mu)\n",
    "\n",
    "        # Part 4.5\n",
    "        e = t.norm(jacL(x, mu))\n",
    "        # print(e)\n",
    "        # Store important information in every iteration\n",
    "#         xSol = np.vstack((xSol, x.detach().numpy())) # Record x values in each iteration\n",
    "#         fVal.append(f(x)[0].item()) # Record f values in each iteration\n",
    "#         alphaSol.append(alpha) # Record alpha values in each iteration\n",
    "#         eVal.append(e)\n",
    "        print(f'k: {k}, x: {x}\\n')\n",
    "        k += 1\n",
    "#         print (f\"Iteration: {k:<5} Alpha: {alpha:<10} x: {str(x.detach().numpy()) :<40} f(x): {fVal[k]:<20} Error: {e:<20}\")\n",
    "    # return xSol, fVal, alphaSol, eVal\n",
    "    # return xSol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2cb977-eebf-4b9c-b9a6-1cbac9d724bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0, x: tensor([0.7500, 1.5000])\n",
      "\n",
      "k: 1, x: tensor([0.8632, 1.5130])\n",
      "\n",
      "k: 2, x: tensor([0.9263, 1.5082])\n",
      "\n",
      "k: 3, x: tensor([0.9668, 1.5000])\n",
      "\n",
      "k: 4, x: tensor([0.9936, 1.4915])\n",
      "\n",
      "k: 5, x: tensor([1.0120, 1.4840])\n",
      "\n",
      "k: 6, x: tensor([1.0250, 1.4777])\n",
      "\n",
      "k: 7, x: tensor([1.0343, 1.4727])\n",
      "\n",
      "k: 8, x: tensor([1.0410, 1.4688])\n",
      "\n",
      "k: 9, x: tensor([1.0460, 1.4657])\n",
      "\n",
      "k: 10, x: tensor([1.0496, 1.4634])\n",
      "\n",
      "k: 11, x: tensor([1.0523, 1.4616])\n",
      "\n",
      "k: 12, x: tensor([1.0543, 1.4603])\n",
      "\n",
      "k: 13, x: tensor([1.0558, 1.4593])\n",
      "\n",
      "k: 14, x: tensor([1.0569, 1.4585])\n",
      "\n",
      "k: 15, x: tensor([1.0577, 1.4579])\n",
      "\n",
      "k: 16, x: tensor([1.0583, 1.4575])\n",
      "\n",
      "k: 17, x: tensor([1.0588, 1.4571])\n",
      "\n",
      "k: 18, x: tensor([1.0592, 1.4569])\n",
      "\n",
      "k: 19, x: tensor([1.0594, 1.4567])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = t.tensor([1., 0.], dtype=t.float, requires_grad=True)\n",
    "mu = t.tensor([0., 0.], dtype=t.float, requires_grad=True)\n",
    "W = t.eye(n, dtype=t.float)\n",
    "wj = t.tensor([0., 0.], dtype=t.float)\n",
    "SQP(x, mu, W, wj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f166ba6-bfc1-4978-93fa-bfe2c1c5a55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae193bcd-5721-421a-b898-96812cf2cdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f623240-8d52-42d6-abc1-d29586007669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c8d11-7da8-4971-98b5-25e328426c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e953ea7-ab2f-4452-82dc-6d7b57c3ce94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
