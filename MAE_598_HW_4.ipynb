{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706924fe-edb5-495e-ae6b-83d60a7c4bae",
   "metadata": {},
   "source": [
    "# MAE 598: Design Optimization - Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45526de2-5165-4002-be62-738f4c700656",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18876731-fa41-4b17-a699-8ba6b13f6c30",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d03e1-61d6-4229-91a0-d8d913731608",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e52014-db0b-4b78-8aa4-6dcab96e959e",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33088a60-e391-4444-bf72-0c36aa0c23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.autograd.functional import jacobian\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1c8e12b-60d7-4349-a149-aa3479122d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\"\"\"\n",
    "Decision variable: x0\n",
    "State variables: x1, x2\n",
    "\"\"\"\n",
    "m = 2\n",
    "n = 3\n",
    "\n",
    "def f(x):\n",
    "    f = lambda x: x[0] ** 2 + x[1] ** 2 + x[2] ** 2\n",
    "    # Define the constraints\n",
    "    h1 = lambda x: ((x[0] ** 2) / 4) + ((x[1] ** 2) / 5) + ((x[2] ** 2) / 25) - 1\n",
    "    h2 = lambda x: x[0] + x[1] - x[2]\n",
    "    \n",
    "    return f(x), h1(x), h2(x)\n",
    "\n",
    "# Part 2\n",
    "#Defining input tensors\n",
    "# x = Variable(t.tensor([1., 1., 1.], dtype=t.float64), requires_grad=True)\n",
    "x = t.tensor([1., 1., 1.], dtype=t.float, requires_grad=True)\n",
    "\n",
    "# Reduced Gradient (Analytically computed)\n",
    "dfdd_analytical = lambda x: ((-5 * x[0] * x[2]) + (-21 * x[0] * x[2]) + (16 * x[1] * x[2])) / (10 * x[1] + 2 * x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6548e605-511b-4670-8f7c-13cf1edd163e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions evaluated at the initial gues:\n",
      "  (tensor(3., grad_fn=<AddBackward0>), tensor(-0.5100, grad_fn=<SubBackward0>), tensor(1., grad_fn=<SubBackward0>))\n",
      "\n",
      "Jacobian evaluated at the initial guess:\n",
      " (tensor([2., 2., 2.]), tensor([0.5000, 0.4000, 0.0800]), tensor([ 1.,  1., -1.]))\n"
     ]
    }
   ],
   "source": [
    "print('Functions evaluated at the initial gues:\\n ', f(x))\n",
    "print('\\nJacobian evaluated at the initial guess:\\n', jacobian(f, (x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97c26f2b-8fad-4148-8a52-edb227d84095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian:\n",
      " tensor([[ 2.0000,  2.0000,  2.0000],\n",
      "        [ 0.5000,  0.4000,  0.0800],\n",
      "        [ 1.0000,  1.0000, -1.0000]])\n"
     ]
    }
   ],
   "source": [
    "J = t.zeros((len(j), len(j)))\n",
    "for p in range(len(j)):\n",
    "   J[p] =  jacobian(f, (x))[p]\n",
    "print('Jacobian:\\n', J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3edb4881-6c8e-4e5e-84c4-64890fce4d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced gradient: tensor(-0.8333)\n",
      "Analytical calculation tensor(-0.8333, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "# Reduced gradient\n",
    "dfdd = J[0,0] - J[0,1:] @ np.linalg.inv(J[1:,1:]) @ J[1:,0]\n",
    "\n",
    "print('Reduced gradient:', dfdd)\n",
    "print('Analytical calculation', dfdd_analytical(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c0f778e-20cd-4ca8-be10-1d15411c98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSolve(f, x, m=m, n=n, epochs=200, Lambda=10.):\n",
    "    H = t.zeros((m,1))\n",
    "    J = t.zeros((n, n))\n",
    "    # Lambda = 50\n",
    "\n",
    "    for q in range(epochs):\n",
    "        for r in range(m):\n",
    "           H[r] =  f(x)[1:][r]\n",
    "        # print('\\nH: ', H)\n",
    "\n",
    "        for p in range(n):\n",
    "           J[p] =  jacobian(f, (x))[p]\n",
    "        # print('Jacobian:\\n', J)\n",
    "\n",
    "\n",
    "        delta = t.inverse(J[1:,1:].T @ J[1:,1:] + Lambda * t.eye(2)) @ J[1:,1:].T @ H\n",
    "        # print(delta.shape)\n",
    "\n",
    "        with t.no_grad():\n",
    "            x[1:] = x[1:] - delta.T\n",
    "\n",
    "        if q % 20 == 19:\n",
    "            print(f'\\nEpoch [{q}]: [dk, sk] --> {x}')\n",
    "            \n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e7e683f-5814-43f5-9663-e92994aa8761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [19]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [39]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [59]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [79]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [99]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [119]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [139]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [159]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [179]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      "Epoch [199]: [dk sk] --> tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n",
      "\n",
      " Point x:  tensor([1.0000, 1.5614, 2.5614], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Find the feasible point based on the initial gues of decision variables\n",
    "x = LMSolve(f, x)\n",
    "print('\\n Point x: ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b72772-a115-4351-950a-b8082698478f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 17\u001b[0m dk0 \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m dfdd\n\u001b[0;32m     18\u001b[0m sk0 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m t\u001b[38;5;241m.\u001b[39mfrom_numpy(alpha \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(J[\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m@\u001b[39m J[\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m J[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     19\u001b[0m func \u001b[38;5;241m=\u001b[39m f(t\u001b[38;5;241m.\u001b[39mhstack((dk0, sk0)))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "# Initialization\n",
    "t0 = 0.5\n",
    "e = np.linalg.norm(dfdd)\n",
    "tol = 1e-4 # Error threshold\n",
    "K = 50 # Max no. of iterations\n",
    "# xSol = x.T\n",
    "# fVal = [f(x)[0]]\n",
    "# alphaSol = [1]\n",
    "\n",
    "k = 0\n",
    "while e > tol:\n",
    "\n",
    "    alpha = 1\n",
    "    i = 0\n",
    "    \n",
    "    dk0 = x[0] - alpha * dfdd\n",
    "    sk0 = x[1:] + t.from_numpy(alpha * np.linalg.inv(J[1:,1:]) @ J[1:,0] * J[0,0])\n",
    "    func = f(t.hstack((dk0, sk0)))[0].item()\n",
    "    phi = f(x)[0].item() - (t0 * alpha * dfdd ** 2) \n",
    "    \n",
    "    # Part 4.1\n",
    "    # Inexact line search\n",
    "    while func > phi and i < K:\n",
    "        alpha = 0.5 * alpha\n",
    "        dk0 = x[0] - alpha * dfdd\n",
    "        sk0 = x[1:] + t.from_numpy(alpha * np.linalg.inv(J[1:,1:]) @ J[1:,0] * J[0,0])\n",
    "        func = f(t.hstack((dk0, sk0)))[0].item()\n",
    "        phi = f(x)[0].item() - (t0 * alpha * dfdd ** 2) \n",
    "        print(f'Iteration: {i}, alpha: {alpha}')\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # Part 4.2\n",
    "    # Tensor\n",
    "    dk0 = x[0] - alpha * dfdd\n",
    "    # Part 4.3\n",
    "    sk0 = x[1:] + t.from_numpy(alpha * np.linalg.inv(J[1:,1:]) @ J[1:,0] * J[0,0])\n",
    "    \n",
    "    \n",
    "    # Part 4.4\n",
    "    # LM Solver\n",
    "    Lambda = 10\n",
    "    for q in range(10):\n",
    "        h = f(t.hstack((dk0, sk0)))[1:,:].item()\n",
    "        j = jacobian(f, (t.hstack((dk0, sk0))))\n",
    "        J = np.zeros((len(j), len(j)))\n",
    "        for p in range(len(j)):\n",
    "           J[p] =  j[p].detach().numpy()\n",
    "        print(J)\n",
    "        \n",
    "        delta = np.linalg.inv(J[1:,1:].T @ J[1:,1:] + Lambda * np.eye(3)) @ J[1:,1:].T @ h\n",
    "    \n",
    "        sk0 = sk0 - delta\n",
    "\n",
    "    \n",
    "    \n",
    "    # Update x\n",
    "    x[0] = dk0\n",
    "    x[1:] = sk0\n",
    "    \n",
    "    # Part 4.5\n",
    "    \n",
    "    \n",
    "    j = jacobian(f, (x))\n",
    "    J = np.zeros((len(j), len(j)))\n",
    "    for p in range(len(j)):\n",
    "       J[p] =  j[p].detach().numpy()\n",
    "    print(J)\n",
    "    \n",
    "    dfdd = J[0,0] - J[0,1:] @ np.linalg.inv(J[1:,1:]) @ J[1:,0]\n",
    "    e = np.linalg.norm(dfdd)\n",
    "    \n",
    "    \n",
    "    # xSol = np.concatenate((xSol, x.T), axis=0)  # Record x values in each iteration\n",
    "    # fVal.append(f(x)[0]) # Record f values in each iteration\n",
    "    # alphaSol.append(alpha) # Record alpha values in each iteration\n",
    "\n",
    "    k += 1\n",
    "    print (f\"Iteration: {k:<5} Alpha: {alpha:<10} x: {str(x.T[0, :]) :<30} f(x): {fVal[k]:<30}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a800d-6b8e-42ad-bed0-426f87d786b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cee21f-76e1-4bae-9976-ba0ca824ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nGRG\\n\")\n",
    "\n",
    "# # Initial guess   \n",
    "# x1 = np.array([[0], [0]])\n",
    "# print('\\nSolution #1\\n')\n",
    "# xSol1, fVal1, alphaSol1 = newt(x1)\n",
    "# # Convergence analysis\n",
    "# yplt1 = abs(np.array(fVal1) - fStar * np.ones([1, len(fVal1)])[0])\n",
    "# # Plot results\n",
    "# print(\"\\nConvergence plot\\n\")\n",
    "# plt.semilogy(range(1, len(fVal1)+1), yplt1, \"rs-\")\n",
    "# plt.xlim(1, 50)\n",
    "# plt.xticks(ticks=range(1, len(fVal1)+1), labels=range(1, len(fVal1)+1))\n",
    "# plt.xlabel(\"Iterations (k)\")\n",
    "# plt.ylabel(\"log|f_k - f*|\")\n",
    "# plt.title(\"Convergence analysis 1\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52e951-ac55-4f36-89b5-4dc376751811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d7a7fa-9aeb-4402-852b-b6d9693b7fae",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2eacf-4bc7-4691-83b6-47245ea6269b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef95de-8563-4112-8c40-160930de8e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
