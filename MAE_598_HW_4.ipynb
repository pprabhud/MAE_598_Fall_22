{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706924fe-edb5-495e-ae6b-83d60a7c4bae",
   "metadata": {},
   "source": [
    "# MAE 598: Design Optimization - Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45526de2-5165-4002-be62-738f4c700656",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18876731-fa41-4b17-a699-8ba6b13f6c30",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d03e1-61d6-4229-91a0-d8d913731608",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63c603-2aaf-42a0-9a5d-00389ceb9ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "To maximize the given objective function, we formulate a minimization problem for the negative of the given function.\n",
    "\n",
    "Objective function\n",
    "\n",
    "$$ \\min_{x_{1}, x_{2}, x_{3}} \\quad f(x) = - x_{1} x_{2} - x_{2} x_{3} - x_{1} x_{3} $$\n",
    "\n",
    "$$ s.t. \\quad h(x) = x_{1} + x_{2} + x_{3} - 3 = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca35c1b-9897-457e-a7b4-97d023c9ae93",
   "metadata": {},
   "source": [
    "Formulate the Langrangian\n",
    "\n",
    "$$ \\mathcal{L} = - x_{1} x_{2} - x_{2} x_{3} - x_{1} x_{3} + \\lambda_1 (x_{1} + x_{2} + x_{3} - 3) $$\n",
    "\n",
    "\n",
    "$${\n",
    "\\nabla_x \\mathcal{L} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "- x_2 - x_3 + \\lambda_1 \\\\\n",
    "- x_1 - x_3 + \\lambda_1 \\\\\n",
    "- x_2 - x_1 + \\lambda_1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "}$$\n",
    "\n",
    "$${\n",
    "\\nabla_\\lambda \\mathcal{L} \n",
    "=\n",
    "x_{1} + x_{2} + x_{3} - 3 = 0\n",
    "}$$\n",
    "\n",
    "Solving the four euqations above, we get:\n",
    "\n",
    "$${ \n",
    "x_{1} = x_{2} = x_{3}  = 1 \\\\\n",
    "\\lambda = 2\n",
    "}$$\n",
    "\n",
    "\n",
    "Computing the Hessian of the Lagrangian\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _{xx}\n",
    "=\n",
    "\\displaystyle\n",
    "\\begin{bmatrix}\n",
    "0 & - 1 & - 1 \\\\\n",
    "-1 & 0 & -1 \\\\\n",
    "-1 & -1 & 0 \n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf9ef0-d103-48f7-a183-dfdd27f2bfe3",
   "metadata": {},
   "source": [
    "Checking Second Order sufficient conditions\n",
    "\n",
    "\n",
    "$$\n",
    "d_x^T \\ \\mathcal{L} _{xx} \\ d_x\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "dx_1 & dx_2 & dx_3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "0 & - 1 & - 1 \\\\\n",
    "-1 & 0 & -1 \\\\\n",
    "-1 & -1 & 0 \n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "dx_1 \\\\\n",
    "dx_2 \\\\\n",
    "dx_3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "- 2 dx_{1} dx_{2} - 2 dx_{2} dx_{3} - 2 dx_{1} dx_{3}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "\\frac{\\partial{h}}{\\partial{x}} dx = 0\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial{h}}{\\partial{x_1}} & \\frac{\\partial{h}}{\\partial{x_2}} & \\frac{\\partial{h}}{\\partial{x_3}}\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "dx_1 \\\\\n",
    "dx_2 \\\\\n",
    "dx_3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "dx_1 \\\\\n",
    "dx_2 \\\\\n",
    "dx_3\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "0\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "dx_1 + dx_2 + dx_3 = 0\n",
    "\\\\\n",
    "dx_1 = - dx_2 - dx_3\n",
    "$$\n",
    "\n",
    "Substituting this result into the first condition, we get:\n",
    "$$\n",
    "d_x^T \\ \\mathcal{L} _{xx} \\ d_x\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "- 2 \\ (- dx_2 - dx_3) \\ dx_{2} - 2 \\ dx_{2} \\ dx_{3} - 2 \\ (- dx_2 - dx_3) \\ dx_{3}\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "- 2 \\ (- dx_2^2 - dx_{2} dx_{3} - dx_{2} dx_{3} - dx_{3}^2 + dx_{2} dx_{3})\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "2 \\ dx_2^2 + 2 \\ dx_{3}^2 + 2 \\ dx_{2} dx_{3}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "d_x^T \\ \\mathcal{L} _{xx} \\ d_x\n",
    "\\quad\n",
    "=\n",
    "\\quad\n",
    "2 \\ \\Big[(dx_{2} + \\frac{dx_{3}}{2})^2 + \\frac{3 \\ dx_{3}^2}{4}\\Big] \\ge 0\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "If $ dx_{2} = 0 $ and $ dx_{3} = 0 $, then from the second condition $ dx_{1} = 0 $ as well. This does not produce a valid perturbation.\n",
    "\n",
    "\n",
    "$$\n",
    "\\therefore\n",
    "d_x^T \\ \\mathcal{L} _{xx} \\ d_x\n",
    "=\n",
    "2 \\ \\Big[(dx_{2} + \\frac{dx_{3}}{2})^2 + \\frac{3 \\ dx_{3}^2}{4}\\Big] > 0\n",
    "\\\\\n",
    "$$\n",
    "when $ dx $ is feasible.\n",
    "\n",
    "The solution $ x = [1, 1, 1] $ is an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3b627-a5e6-42d6-9b22-3050d78fa50d",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e52014-db0b-4b78-8aa4-6dcab96e959e",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33088a60-e391-4444-bf72-0c36aa0c23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1c8e12b-60d7-4349-a149-aa3479122d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\"\"\"\n",
    "Decision variable: x0\n",
    "State variables: x1, x2\n",
    "\"\"\"\n",
    "\n",
    "m = 2\n",
    "n = 3\n",
    "\n",
    "def f(x):\n",
    "    f = lambda x: x[0] ** 2 + x[1] ** 2 + x[2] ** 2\n",
    "    # Define the constraints\n",
    "    h1 = lambda x: ((x[0] ** 2) / 4) + ((x[1] ** 2) / 5) + ((x[2] ** 2) / 25) - 1\n",
    "    h2 = lambda x: x[0] + x[1] - x[2]\n",
    "    \n",
    "    return f(x), h1(x), h2(x)\n",
    "\n",
    "# Part 2\n",
    "#Defining input tensor\n",
    "x = Variable(t.tensor([1., 1., 1.], dtype=t.float64), requires_grad=True)\n",
    "\n",
    "# Reduced Gradient (Analytically computed)\n",
    "dfdd_analytical = lambda x: ((-5 * x[0] * x[2]) + (-21 * x[0] * x[2]) + (16 * x[1] * x[2])) / (10 * x[1] + 2 * x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a490ab-18e9-4441-9c4e-c85d2fff9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Jacobian\n",
    "def jac(x, n=n):\n",
    "    J = t.zeros((n, n))\n",
    "    for i in range(n):\n",
    "       J[i] =  jacobian(f, (x))[i]\n",
    "    return J\n",
    "\n",
    "# Evaluate Constraints\n",
    "def hFunc(x, m=m, n=n):\n",
    "    H = t.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        # print(n-m+r)\n",
    "        H[i] =  f(x)[n-m+i]\n",
    "        # print(f(x)[n-m+r])\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edb4881-6c8e-4e5e-84c4-64890fce4d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced gradient: tensor(-0.8333)\n",
      "Analytical calculation tensor(-0.8333, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "# Reduced gradient\n",
    "dfdd = lambda J: J[0,0] - J[0,1:] @ t.pinverse(J[1:,1:]) @ J[1:,0]\n",
    "\n",
    "print('Reduced gradient:', dfdd(jac(x)))\n",
    "print('Analytical calculation', dfdd_analytical(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0f778e-20cd-4ca8-be10-1d15411c98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSolve(x, m=m, n=n, epochs=60, Lambda=1.):      \n",
    "    for i in range(epochs):\n",
    "        H = hFunc(x)\n",
    "        J =  jac(x)\n",
    "        delta = t.pinverse(J[n-m:, n-m:].T @ J[n-m:, n-m:] + Lambda * t.eye(m)) @ J[n-m:, n-m:].T @ H\n",
    "        with t.no_grad():\n",
    "            x[n-m:] = x[n-m:] - delta.T\n",
    "        e = t.norm(H)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b352daad-4b12-422a-bff0-0e7a1334aa5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def updateX(x, alpha):\n",
    "    xn = t.zeros(3)\n",
    "    J = jac(x)\n",
    "    xn[0] = x[0] - alpha * dfdd(J)\n",
    "    xn[1:] = x[1:] + (alpha * t.pinverse(J[1:,1:]) @ J[1:,0].reshape(2,-1) *  dfdd(J)).T[0]\n",
    "    return xn\n",
    "\n",
    "\n",
    "def lineSearch(x, t0=0.5, K=25):\n",
    "    alpha = 1\n",
    "    i = 0\n",
    "    \n",
    "    func = f(updateX(x, alpha))[0]\n",
    "    phi = f(x)[0] - (t0 * alpha * dfdd(jac(x)) ** 2)\n",
    "    \n",
    "    while func > phi and i < K:\n",
    "        alpha = 0.5 * alpha\n",
    "        func = f(updateX(x, alpha))[0]\n",
    "        phi = f(x)[0] - (t0 * alpha * dfdd(jac(x)) ** 2)\n",
    "\n",
    "        i += 1\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9b72772-a115-4351-950a-b8082698478f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Initialization\n",
    "def GRG(x):\n",
    "    e = t.norm(dfdd(jac(x)))\n",
    "    tol = 1e-3 # Error threshold\n",
    "\n",
    "    xSol = x.detach().numpy()\n",
    "    fVal = [f(x)[0].item()]\n",
    "    alphaSol = [1]\n",
    "    eVal = [e]\n",
    "\n",
    "    k = 0\n",
    "    while e > tol:\n",
    "        # Part 4.1\n",
    "        # Inexact line search\n",
    "        alpha = lineSearch(x)\n",
    "\n",
    "        # Part 4.2 and 4.3\n",
    "        J = jac(x) \n",
    "        with t.no_grad():\n",
    "            x[0] = x[0] - alpha * dfdd(J)\n",
    "            x[1:] = x[1:] + (alpha * t.pinverse(J[1:,1:]) @ J[1:,0].reshape(2,-1) *  dfdd(J)).T[0]\n",
    "\n",
    "        # Part 4.4\n",
    "        # LM Solver\n",
    "        x = LMSolve(x)\n",
    "\n",
    "        # Part 4.5\n",
    "        e = t.norm(dfdd(jac(x)))\n",
    "        \n",
    "        xSol = np.vstack((xSol, x.detach().numpy())) # Record x values in each iteration\n",
    "        fVal.append(f(x)[0].item()) # Record f values in each iteration\n",
    "        alphaSol.append(alpha) # Record alpha values in each iteration\n",
    "        eVal.append(e)\n",
    "\n",
    "        k += 1\n",
    "        print (f\"Iteration: {k:<5} Alpha: {alpha:<10} x: {str(x.detach().numpy()) :<40} f(x): {fVal[k]:<20} Error: {e:<20}\")\n",
    "    return xSol, fVal, alphaSol, eVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0cee21f-76e1-4bae-9976-ba0ca824ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feasible starting point:  tensor([0.1000, 2.0217, 2.1217], dtype=torch.float64, requires_grad=True)\n",
      "Reduced gradient: tensor(2.5823)\n",
      "Analytical calculation\n",
      " tensor(2.5803, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "GRG\n",
      "\n",
      "Iteration: 1     Alpha: 0.25       x: [-0.54557415  2.04420139  1.49862724]    f(x): 6.722294098143511    Error: 3.0616188049316406  \n",
      "Iteration: 2     Alpha: 0.125      x: [-0.9282765   1.92936347  1.00108697]    f(x): 5.5863157917200255   Error: 2.7880258560180664  \n",
      "Iteration: 3     Alpha: 0.125      x: [-1.27677974  1.71018273  0.43340305]    f(x): 4.742729666089317    Error: 1.9143002033233643  \n",
      "Iteration: 4     Alpha: 0.0625     x: [-1.3964235   1.59823557  0.20181213]    f(x): 4.545083659483026    Error: 1.3571269512176514  \n",
      "Iteration: 5     Alpha: 0.0625     x: [-1.48124393  1.50243396  0.02119016]    f(x): 4.451840411348006    Error: 0.8160951137542725  \n",
      "Iteration: 6     Alpha: 0.0625     x: [-1.53224988  1.4364645  -0.09578523]    f(x): 4.420394752787838    Error: 0.40369129180908203 \n",
      "Iteration: 7     Alpha: 0.03125    x: [-1.54486523  1.41900361 -0.1258616 ]    f(x): 4.416020976915923    Error: 0.28841662406921387 \n",
      "Iteration: 8     Alpha: 0.03125    x: [-1.55387825  1.40622466 -0.14765358]    f(x): 4.413806990349655    Error: 0.20231342315673828 \n",
      "Iteration: 9     Alpha: 0.03125    x: [-1.56020054  1.39710335 -0.16309719]    f(x): 4.412724195138158    Error: 0.1399238109588623  \n",
      "Iteration: 10    Alpha: 0.03125    x: [-1.56457316  1.39071685 -0.17385631]    f(x): 4.4122085571311045   Error: 0.09577131271362305 \n",
      "Iteration: 11    Alpha: 0.03125    x: [-1.56756602  1.38630809 -0.18125793]    f(x): 4.411967765075608    Error: 0.0650627613067627  \n",
      "Iteration: 12    Alpha: 0.03125    x: [-1.56959923  1.38329535 -0.18630388]    f(x): 4.411856884784105    Error: 0.043967247009277344\n",
      "Iteration: 13    Alpha: 0.03125    x: [-1.5709732   1.38125129 -0.18972192]    f(x): 4.411806327630644    Error: 0.02960515022277832 \n",
      "Iteration: 14    Alpha: 0.03125    x: [-1.57189837  1.3798712  -0.19202717]    f(x): 4.411783430305542    Error: 0.019883155822753906\n",
      "Iteration: 15    Alpha: 0.03125    x: [-1.57251971  1.37894263 -0.19357709]    f(x): 4.411773108992794    Error: 0.013333559036254883\n",
      "Iteration: 16    Alpha: 0.03125    x: [-1.57293639  1.37831917 -0.19461722]    f(x): 4.411768470324686    Error: 0.008928298950195312\n",
      "Iteration: 17    Alpha: 0.03125    x: [-1.5732154   1.37790135 -0.19531405]    f(x): 4.411766390680494    Error: 0.005975961685180664\n",
      "Iteration: 18    Alpha: 0.0625     x: [-1.57358889  1.3773416  -0.19624729]    f(x): 4.411764897899219    Error: 0.0020165443420410156\n",
      "Iteration: 19    Alpha: 0.125      x: [-1.57384096  1.37696356 -0.1968774 ]    f(x): 4.411764726440828    Error: 0.0006597042083740234\n",
      "\n",
      "Convergence plot\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the feasible point based on the initial gues of decision variables\n",
    "x = t.tensor([0.1, 1., 1.], dtype=t.float64, requires_grad=True)\n",
    "x = LMSolve(x)\n",
    "print('Feasible starting point: ', x)\n",
    "print('Reduced gradient:', dfdd(jac(x)))\n",
    "print('Analytical calculation\\n', dfdd_analytical(x))\n",
    "\n",
    " \n",
    "print(\"\\nGRG\\n\")\n",
    "xSol, fVal, alphaSol, eVal = GRG(x)\n",
    "# Convergence analysis\n",
    "\n",
    "# Plot results\n",
    "print(\"\\nConvergence plot\\n\")\n",
    "plt.plot(range(1, len(fVal)+1), eVal, \"rs-\")\n",
    "# plt.xlim(1, 50)\n",
    "plt.xticks(ticks=range(1, len(fVal)+1), labels=range(1, len(fVal)+1))\n",
    "plt.xlabel(\"Iterations (k)\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Convergence analysis\")\n",
    "plt.grid(axis='y', color='0.95')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d06de44a-f8d0-4980-9497-259b719036fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot data\n",
    "# x0, x1, x2 = np.mgrid[-2:2:50j, -2:2:50j, -5:5:50j]\n",
    "# f([x0, x1, x2])[0]\n",
    "\n",
    "# fig1 = plt.figure(figsize=(10,10))\n",
    "# ax1 = fig1.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax1.scatter([x0, x1, x2], f([x0, x1, x2]), alpha=0.5, cmap=\"rainbow\", label=\"Actual function\")\n",
    "# # ax1.scatter(xp[:, 0], xp[:, 1], yp, alpha=1, color=\"black\", label=\"Initial point\", linewidth=2)\n",
    "# ax1.set_xlabel(\"[x1]\")\n",
    "# ax1.set_ylabel(\"[x2]\")\n",
    "# ax1.set_zlabel(\"[f]\")\n",
    "# ax1.set_title(\"Function plot with initial samples\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7a7fa-9aeb-4402-852b-b6d9693b7fae",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2eacf-4bc7-4691-83b6-47245ea6269b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef95de-8563-4112-8c40-160930de8e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
